#cloud-config
autoinstall:
  version: 1
  identity:
    hostname: fluidos-node-00
    realname: Fluidos cluster user
    username: edge
    # mkpasswd -m sha-512
    # Password: fluidos
    password: $6$D.jfv7J8MZ27ohBd$nUqO0YhzbTbwdWXCaH..oHUtG9o0p2r6P7TONXbEMsH5Zz7aHSwTI1D/WBxv6FP2dfQEfJHGN3RQUG67VKJuD1
  refresh-installer:
  update: yes
  locale: en_US
  keyboard:
    layout: es
    # variant: es
  source:
    id: "ubuntu-server"
  ssh:
    install-server: yes
    authorized-keys:
      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCtkQFf7sa+G1oAGkPC2fMR+qOqcE651SToEyVbR6aDFR9kYLSFLvzUA1W+hjDsI1uL5SuOQju1kDDDnNO0SjQOsffqw44L3D9CXqNPIAGs+6lBffDGd9A6e5yLpOuaXM5t9dMBq2SWV2Frq8gu0CR3NyHtFCzu87ghlKzaelaGWdIeyR+2HqtQr3t+ykCF5u0/+MLGWEHISpl+aV17+lvRB8qRNE0hZm7lSWTgJ2gRFVIGy69tsUCYf9+0KJDkM3sfvxzM2HyKNN60gkGDTH0BA4/ZTzqs8qbCylD1Jhgl+0ZNaIg6OkhyFBzESxrQpQkexOTtygtpv6YJM2liZTV7
    allow-pw: yes
  updates: all
  apt:
    mirror-selection:
      primary:
        - uri: http://archive.ubuntu.com/ubuntu
    sources:
      docker.list:
        source: >
          deb [arch=amd64] https://download.docker.com/linux/ubuntu jammy stable
        keyid: 9DC858229FC7DD38854AE2D88D81803C0EBFCD88
      kubernetes.list:
        source: >
          deb [arch=amd64] https://apt.kubernetes.io/ kubernetes-xenial main
        keyid: A362B822F6DEDC652817EA46B53DC80D13EDEF05
  network:
    network:
      version: 2
      ethernets:
        eth0:
          dhcp4: yes
          optional: yes
        eth1:
          dhcp4: yes
          optional: true
  storage:
    layout:
      name: lvm
      match:
        ssd: yes
      sizing-policy: scaled
  packages:
    - gnupg2
    - apt-transport-https
    - jq
    - powerline
    - fonts-powerline
    # - fzf
    - ack-grep
    - net-tools
    - containerd.io
    - docker-ce
    - docker-ce-cli
    - docker-compose-plugin
    # kube tools package order matters (version specific)
    - kubelet=1.26.4-00
    - kubectl=1.26.4-00
    - kubeadm=1.26.4-00
  late-commands:
    - sed -i 's#^/swap.img#\#/swap.img#' /target/etc/fstab
    - >
      curtin in-target --target=/target --
      apt-mark hold kubelet kubeadm kubectl
    - >
      curtin in-target --target=/target --
      ufw allow "OpenSSH"
    - >
      curtin in-target --target=/target --
      ufw allow 6443/tcp
    - >
      curtin in-target --target=/target --
      ufw allow 2379:2380/tcp
    - >
      curtin in-target --target=/target --
      ufw allow 10250/tcp
    - >
      curtin in-target --target=/target --
      ufw allow 10259/tcp
    - >
      curtin in-target --target=/target --
      ufw allow 10257/tcp
    - >
      curtin in-target --target=/target --
      ufw allow 179/tcp
    - >
      curtin in-target --target=/target --
      ufw allow 4789/udp
    - >
      curtin in-target --target=/target --
      ufw allow 4789/tcp
    - >
      curtin in-target --target=/target --
      ufw allow 2379/tcp
    - >
      curtin in-target --target=/target --
      ufw enable
    - >
      curtin in-target --target=/target --
      curl -fsSL -o get_helm.sh
      https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
    - >
      curtin in-target --target=/target --
      chmod 700 get_helm.sh
    - >
      curtin in-target --target=/target --
      ./get_helm.sh
    - >
      curtin in-target --target=/target --
      rm get_helm.sh
    - >
      curl -L
      https://github.com/projectcalico/calico/releases/latest/download/calicoctl-linux-amd64
      -o
      /target/usr/local/bin/calicoctl
    - chmod +x /target/usr/local/bin/calicoctl
    # # use this for 0.8.1 or any other version not the latest
    # - >
    #   curl -L
    #   https://github.com/liqotech/liqo/releases/download/v0.8.1/liqoctl-linux-amd64
    #   -o
    #   /target/usr/local/bin/liqoctl
    - >
      curl -L
      https://github.com/liqotech/liqo/releases/latest/download/liqoctl-linux-amd64
      -o
      /target/usr/local/bin/liqoctl
    - chmod 0755 /target/usr/local/bin/liqoctl
    - chown root:root /target/usr/local/bin/liqoctl
    - wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O yq
    - chmod +x yq
    - mv yq /target/usr/local/bin/yq
  user-data:
    write_files:
      - path: /etc/modules-load.d/k8s.conf
        permissions: '0644'
        content: |
          overlay
          br_netfilter
      - path: /etc/sysctl.d/k8s.conf
        permissions: '0644'
        content: |
          net.bridge.bridge-nf-call-iptables  = 1
          net.bridge.bridge-nf-call-ip6tables = 1
          net.ipv4.ip_forward                 = 1
      - path: /usr/local/bin/update_k9s
        permissions: '0755'
        content: |
          #!/bin/bash
          # Description:   k9s updater
          # Company:       Robotnik Automation S.L.L.
          # Creation Year: 2023
          # Author:        Guillem Gari <ggari@robotnik.es>
          #
          #
          # Copyright (c) 2023, Robotnik Automation S.L.
          # All rights reserved.
          #
          # Redistribution and use in source and binary forms, with or without
          # modification, are permitted provided that the following conditions are met:
          #     * Redistributions of source code must retain the above copyright
          #       notice, this list of conditions and the following disclaimer.
          #     * Redistributions in binary form must reproduce the above copyright
          #       notice, this list of conditions and the following disclaimer in the
          #       documentation and/or other materials provided with the distribution.
          #     * Neither the name of the Robotnik Automation S.L.L. nor the
          #       names of its contributors may be used to endorse or promote products
          #       derived from this software without specific prior written permission.
          #
          # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
          # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
          # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
          # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL Robotnik Automation S.L.L.
          # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
          # OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
          # PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
          # OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
          # WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
          # OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
          # EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

          #Colour
          red_colour='\033[0;31m'
          green_colour='\033[0;32m'
          light_purple_colour='\033[1;35m'
          err_colour="${red_colour}"
          nfo_colour="${light_purple_colour}"
          suc_colour="${green_colour}"
          no_colour='\033[0m'

          tool_list=(\
            git \
            curl \
            wget \
            jq \
            tar \
          )

          # url & files
          github_api_url="https://api.github.com"
          github_url="https://github.com"
          github_k9s_user="derailed"
          k9s_repo="k9s"
          k9s_version_url="${github_api_url}/repos/${github_k9s_user}/${k9s_repo}/releases"
          k9s_pkg="k9s_Linux_amd64.tar.gz"
          k9s_local_pkg="/tmp/${k9s_pkg}"
          k9s_download_url='${github_url}/${github_k9s_user}/${k9s_repo}/releases/download/${K9S_VERSION}/${k9s_pkg}'

          #commands
          check_local_k9s_command='k9s version &>/dev/null'
          local_k9s_version_command='$(k9s version | grep Version | sed "s#.*:* ##")'
          get_last_version_command='$(curl -sL ${k9s_version_url} | jq -r ".[0].name")'
          download_last_version_command='rm -rf ${k9s_local_pkg} && wget ${k9s_download_url} -q -O ${k9s_local_pkg}'
          install_k9s_command='cd /tmp && tar -xaf ${k9s_local_pkg} && mv /tmp/k9s /usr/local/bin/k9s && rm -rf ${k9s_local_pkg}'

          err_str_root_permission="You need root privileges try:\nsudo ${0}"

          nfo_str_tool_checking='Checking tools'
          suc_str_tool_check_success='All required tools are available'

          nfo_check_system="Scanning local system"

          suc_str_local_version_k9s='k9s local version ${K9S_LOCAL_VERSION}'
          err_str_local_version_k9s='could not retrieve k9s local version'
          suc_str_available_version_k9s='k9s last avaible version ${K9S_VERSION}'
          err_str_available_version_k9s='could not retrieve k9s last available version'

          nfo_str_update_k9s='Updating k9s to ${K9S_VERSION}'
          succ_str_k9s_already_updated='Already on the k9s version'
          err_str_update_k9s='Error updateing k9s'
          suc_str_update_k9s='k9s updated to ${K9S_VERSION}'


          function print_error() {
            local message="${1}"
            eval "echo -e "'"'"${err_colour}[ERROR]${no_colour}:   ${message}"'"'" 2>&1"
          }

          function print_info() {
            local message="${1}"
            eval "echo -e "'"'"${nfo_colour}[INFO]${no_colour}:    ${message}"'"'""
          }

          function print_success() {
            local message="${1}"
            eval "echo -e "'"'"${suc_colour}[SUCCESS]${no_colour}: ${message}"'"'""
          }

          function check_root_permission() {
            if [[ "${EUID}" = 0 ]]; then
              return 0
            else
              print_error "${err_str_root_permission}"
              return 1
            fi
          }

          function tool_check() {
            local binary="${1}"
            if [[ -z "${binary}" ]];then
              return 1
            fi
            eval "${tool_check_cmd}"
            return $?
          }

          function tools_check() {
            local tools=("${@}")
            print_info "${nfo_str_tool_checking}"
            for tool in "${tools[@]}"; do
              if ! tool_check "${tool}"; then
                print_error "${err_str_required_tool_not_found}"
                return 1
              fi
            done
            print_success "${suc_str_tool_check_success}"
            return 0
          }

          function check_k9s_exits() {
            eval "${check_local_k9s_command}"
            return $?
          }

          function check_k9s_version() {
            eval "K9S_LOCAL_VERSION=${local_k9s_version_command}"
            return $?
          }

          function get_last_available_k9s_version() {
            if ! eval "K9S_VERSION=${get_last_version_command}"; then
              print_error "${err_str_available_version_k9s}"
              return 1
            fi
            return 0
          }

          function there_is_k9s_update() {
            print_info "${nfo_check_system}"
            if ! get_last_available_k9s_version; then
              return 1
            fi
            if ! check_k9s_exits; then
              return 0
            fi
            if ! check_k9s_version; then
              return 1
            fi
            if [[ ${K9S_LOCAL_VERSION} == ${K9S_VERSION} ]]; then
              print_success "${succ_str_k9s_already_updated}"
              return 1
            fi
            print_success "${suc_str_available_version_k9s}"
            return 0
          }

          function download_k9s(){
            eval "k9s_download_url=${k9s_download_url}"
            eval "${download_last_version_command}"
            return $?
          }

          function install_k9s() {
            eval "${install_k9s_command}"
            return $?
          }

          function update_k9s() {
            print_info "${nfo_str_update_k9s}"
            if ! download_k9s; then
              print_err "${err_str_update_k9s}"
              return 1
            fi
            if ! install_k9s; then
              print_err "${err_str_update_k9s}"
              return 1
            fi
            print_success "${suc_str_update_k9s}"
            return 0
          }

          function main() {
            if ! check_root_permission; then
              return 1
            fi
            if ! tools_check "${tool_list[@]}"; then
              return 1
            fi
            if ! there_is_k9s_update; then
              return 0
            fi
            if ! update_k9s; then
              return 1
            fi
            return 0
          }

          main "${@}"
          exit $?
      - path: /root/environment
        permissions: '0644'
        content: |
          #for multimaster control plane
          export VIP=192.168.2.10
          export MASTER_IP=192.168.2.100
          export MASTER_HOSTNAME=fluidos-node-00
          export INTERFACE=eth0
          export CIDR_NET=10.244.0.0/16
          export USE_VIP=true
          export CNI_FLAVOR=flannel
          export CALICO_VERSION=3.25.1
          export FLANNEL_VERSION=0.21.4
          export METALLB_IP_POD="192.168.2.211-192.168.2.219"
          export CLUSTER_NAME=fluidos-cluster-00
      - path: /root/destroy-cluster.sh
        permissions: '0755'
        content: |
          sudo rm -f \
            /etc/cni/net.d/10-calico.conflist \
            /etc/cni/net.d/calico-kubeconfig \
            /etc/cni/net.d/10-flannel.conflist
          sudo kubeadm reset --force
      - path: /root/start-cluster.sh
        permissions: '0755'
        content: |
          #!/bin/bash
          # Description:   cluster start script
          # Company:       Robotnik Automation S.L.
          # Creation Year: 2023
          # Author:        Guillem Gari <ggari@robotnik.es>
          #
          #
          # Copyright (c) 2023, Robotnik Automation S.L.
          # All rights reserved.
          #
          # Redistribution and use in source and binary forms, with or without
          # modification, are permitted provided that the following conditions are met:
          #     * Redistributions of source code must retain the above copyright
          #       notice, this list of conditions and the following disclaimer.
          #     * Redistributions in binary form must reproduce the above copyright
          #       notice, this list of conditions and the following disclaimer in the
          #       documentation and/or other materials provided with the distribution.
          #     * Neither the name of the Robotnik Automation S.L.L. nor the
          #       names of its contributors may be used to endorse or promote products
          #       derived from this software without specific prior written permission.
          #
          # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
          # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
          # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
          # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL Robotnik Automation S.L.L.
          # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
          # OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
          # PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
          # OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
          # WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
          # OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
          # EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

          source ~/.cluster-init/environment

          if [[ ${USE_VIP} == "true" ]]; then
            export KVVERSION=$(curl -sL https://api.github.com/repos/kube-vip/kube-vip/releases | jq -r ".[0].name")

            sudo ctr image pull ghcr.io/kube-vip/kube-vip:$KVVERSION || exit 1
            sudo ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:$KVVERSION vip /kube-vip \
            manifest pod \
                --interface $INTERFACE \
                --address $VIP \
                --controlplane \
                --services \
                --arp \
                --leaderElection | sudo tee /etc/kubernetes/manifests/kube-vip.yaml || exit 1
            sudo kubeadm init \
            --pod-network-cidr=${CIDR_NET} \
            --apiserver-advertise-address=${MASTER_IP} \
            --control-plane-endpoint ${VIP}:6443 \
            --cri-socket unix:///var/run/containerd/containerd.sock \
            --upload-certs \
            --apiserver-cert-extra-sans=127.0.0.1,${MASTER_HOSTNAME},${MASTER_IP} || exit 1
          else
            sudo kubeadm init \
            --pod-network-cidr=${CIDR_NET} \
            --apiserver-advertise-address=${MASTER_IP} \
            --control-plane-endpoint ${MASTER_IP}:6443 \
            --cri-socket unix:///var/run/containerd/containerd.sock \
            --upload-certs \
            --apiserver-cert-extra-sans=127.0.0.1,${MASTER_HOSTNAME},${MASTER_IP} || exit 1

          fi

          mkdir -p $HOME/.kube || exit 1
          sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config || exit 1
          sudo chown $(id -u):$(id -g) $HOME/.kube/config || exit 1

          #to allow the master to act as
          kubectl taint nodes --all node-role.kubernetes.io/control-plane- || exit 1
          if [[ ${CNI_FLAVOR} == "flannel" ]]; then
            kubectl create ns kube-flannel
            kubectl label --overwrite ns kube-flannel pod-security.kubernetes.io/enforce=privileged
            helm repo add flannel https://flannel-io.github.io/flannel/
            helm install flannel --set podCidr="${CIDR_NET}" --namespace kube-flannel flannel/flannel
            # wget \
            # https://raw.githubusercontent.com/flannel-io/flannel/v${FLANNEL_VERSION}/Documentation/kube-flannel.yml
            # sed -i "s#\"Network\": \"10.244.0.0/16\"#\"Network\": \"${CIDR_NET}\"#" kube-flannel.yml
            # kubectl apply -f kube-flannel.yml
          fi
          if [[ ${CNI_FLAVOR} == "calico" ]]; then
            curl https://raw.githubusercontent.com/projectcalico/calico/v${CALICO_VERSION}/manifests/tigera-operator.yaml -O || exit 1
            kubectl create -f tigera-operator.yaml || exit 1
            curl https://raw.githubusercontent.com/projectcalico/calico/v${CALICO_VERSION}/manifests/custom-resources.yaml -O

            sed -i "s#cidr: 192.168.0.0/16#cidr: ${CIDR_NET}#" custom-resources.yaml || exit 1
            yq 'select(document_index == 0) | .spec.calicoNetwork.nodeAddressAutodetectionV4.skipInterface = "liqo.*"' custom-resources.yaml> custom-resources.yaml.1
            yq -i '.spec.calicoNodeDaemonSet.spec.template.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms += [{ "matchExpressions" : [{"key": "liqo.io/type", "operator" : "NotIn", "values": [ "virtual-node"]}] }]' custom-resources.yaml.1
            # yq -i '.spec.CSINodeDriverDaemonSet.spec.template.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms += [{ "matchExpressions" : [{"key": "liqo.io/type", "operator" : "NotIn", "values": [ "virtual-node"]}] }]' custom-resources.yaml.1
            yq 'select(document_index == 1)' custom-resources.yaml> custom-resources.yaml.2
            rm custom-resources.yaml
            touch custom-resources.yaml
            cat custom-resources.yaml.1>>custom-resources.yaml
            echo "---" >>custom-resources.yaml
            cat custom-resources.yaml.2>>custom-resources.yaml
            rm custom-resources.yaml.1 custom-resources.yaml.2
            kubectl create -f custom-resources.yaml || exit 1
          fi
          kubectl get -n kube-system daemonsets.apps kube-proxy -o yaml >kube-proxy-ds.yaml
          yq -i '.spec.template.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms += [{ "matchExpressions" : [{"key": "liqo.io/type", "operator" : "NotIn", "values": [ "virtual-node"]}] }]' kube-proxy-ds.yaml
          kubectl delete -n kube-system daemonsets.apps kube-proxy
          kubectl apply -f kube-proxy-ds.yaml
          rm kube-proxy-ds.yaml
          helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/ || exit 1
          helm install --set 'args={--kubelet-insecure-tls}' --namespace kube-system metrics metrics-server/metrics-server || exit 1
          helm repo add metallb https://metallb.github.io/metallb || exit 1
          helm install --create-namespace --namespace metallb-system metallb metallb/metallb || exit 1


          cat <<EOF > metallb-config.yaml
          ---
          apiVersion: metallb.io/v1beta1
          kind: IPAddressPool
          metadata:
            name: first-pool
            namespace: metallb-system
          spec:
            addresses:
              - ${METALLB_IP_POD}
            autoAssign: true
          ---
          apiVersion: metallb.io/v1beta1
          kind: L2Advertisement
          metadata:
            name: first-pool
            namespace: metallb-system
          spec:
            ipAddressPools:
            - first-pool

          EOF
          metallb_replicas=0
          echo "Waiting for metallb to start up"
          while [ $metallb_replicas -lt 1 ]; do
            metallb_replicas=0
            replicas=$(kubectl get deployments.apps --namespace metallb-system metallb-controller -o json | jq -r ".status.readyReplicas")
            if [[ $replicas =~ [0-9]+ ]]; then
              metallb_replicas=$replicas
            fi
            if [ $metallb_replicas -ge 1 ]; then
              echo "\nMetallb is up"
              sleep 2
              echo "applying metallb configuration"
              if kubectl apply -f metallb-config.yaml; then
                break;
              else
                echo "retry metallb configuration apply"
              fi
            else
              echo -n "."
              sleep 5
            fi
          done
          liqoctl install kubeadm --cluster-name $CLUSTER_NAME || exit 1
          LIQO_SVC_PROTO=$(kubectl get services -n liqo liqo-gateway -o yaml \
          | \
          yq '.spec.ports.[] | select(.name == "wireguard") | .protocol | downcase' \
          )
          LIQO_SVC_PORT=$(kubectl get services -n liqo liqo-gateway -o yaml \
          | \
          yq '.spec.ports.[] | select(.name == "wireguard") | .port ' \
          )
          sudo ufw allow ${LIQO_SVC_PORT}/${LIQO_SVC_PROTO} || exit 1
          liqoctl generate peer-command
    runcmd:
      - systemctl stop containerd
      - mkdir -p /etc/containerd
      - touch /etc/containerd/config.toml
      - containerd config default > /etc/containerd/config.toml
      - >
        sed -i
        's/SystemdCgroup = false/SystemdCgroup = true/'
        /etc/containerd/config.toml
      - systemctl start containerd
      - systemctl enable containerd
      - kubeadm config images pull
      - /usr/local/bin/update_k9s
      - kubeadm completion bash >/etc/bash_completion.d/kubeadm
      - kubectl completion bash >/etc/bash_completion.d/kubectl
      - helm completion bash >/etc/bash_completion.d/helm
      - HOME=/root liqoctl completion bash >/etc/bash_completion.d/liqoctl
      - groupadd docker
      - usermod -aG docker edge
      - >
        sudo -u edge
        git clone --depth 1
        https://github.com/junegunn/fzf.git
        /home/edge/.fzf
      - sudo -u edge /home/edge/.fzf/install --all
      - mkdir -p /home/edge/.cluster-init
      - mv /root/start-cluster.sh /home/edge/.cluster-init/
      - mv /root/destroy-cluster.sh /home/edge/.cluster-init/
      - mv /root/environment /home/edge/.cluster-init/
      - chown -R edge:edge /home/edge/.cluster-init
      - >
        sudo -u edge
        echo
        "source /usr/share/powerline/bindings/bash/powerline.sh"
        >>/home/edge/.bashrc
